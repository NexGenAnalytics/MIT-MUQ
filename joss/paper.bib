
@article{salvatier2016,
  title={Probabilistic programming in Python using PyMC3},
  author={Salvatier, John and Wiecki, Thomas V and Fonnesbeck, Christopher},
  journal={PeerJ Computer Science},
  volume={2},
  pages={e55},
  year={2016},
  publisher={PeerJ Inc.},
  doi={10.7717/peerj-cs.55},
}

@article{cui2016,
  title={Dimension-independent likelihood-informed MCMC},
  author={Cui, Tiangang and Law, Kody JH and Marzouk, Youssef M},
  journal={Journal of Computational Physics},
  volume={304},
  pages={109--137},
  year={2016},
  publisher={Elsevier},
  doi={10.1016/j.jcp.2015.10.008}
}

@misc{nlopt,
author={Steven Johnson},
title={The NLopt nonlinear-optimization package},
howpublished={\url{http://github.com/stevengj/nlopt}},
year={2007}
}

@MISC{eigenweb,
 author = {Ga\"{e}l Guennebaud and Beno\^{i}t Jacob and others},
 title = {Eigen v3},
 howpublished = {\url{http://eigen.tuxfamily.org}},
 year = {2010}
}

@misc{blanco2014nanoflann,
  title        = {nanoflann: a {C}++ header-only fork of {FLANN}, a library for Nearest Neighbor ({NN}) with KD-trees},
  author       = {Blanco, Jose Luis and Rai, Pranjal Kumar},
  howpublished = {\url{https://github.com/jlblancoc/nanoflann}},
  year         = {2014}
}

@article{hindmarsh2005sundials,
  title={{SUNDIALS}: Suite of nonlinear and differential/algebraic equation solvers},
  author={Hindmarsh, Alan C and Brown, Peter N and Grant, Keith E and Lee, Steven L and Serban, Radu and Shumaker, Dan E and Woodward, Carol S},
  journal={ACM Transactions on Mathematical Software (TOMS)},
  volume={31},
  number={3},
  pages={363--396},
  year={2005},
  publisher={ACM},
  doi={10.1145/1089014.1089020}
}

@misc{boost,
    author = "Boost",
    year   = 2015,
    title  = "{Boost C++ Libraries}",
    howpublished = "\url{http://www.boost.org/}"
}

@article{carpenter2017,
  title={Stan: A Probabilistic Programming Language},
  volume={76},
  url={https://www.jstatsoft.org/index.php/jss/article/view/v076i01},
  doi={10.18637/jss.v076.i01},
  abstract={Stan is a probabilistic programming language for specifying statistical models. A Stan program imperatively defines a log probability function over parameters conditioned on specified data and constants. As of version 2.14.0, Stan provides full Bayesian inference for continuous-variable models through Markov chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling. Penalized maximum likelihood estimates are calculated using optimization methods such as the limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm. Stan is also a platform for computing log densities and their gradients and Hessians, which can be used in alternative algorithms such as variational Bayes, expectation propagation, and marginal inference using approximate integration. To this end, Stan is set up so that the densities, gradients, and Hessians, along with intermediate quantities of the algorithm such as acceptance probabilities, are easily accessible. Stan can be called from the command line using the cmdstan package, through R using the rstan package, and through Python using the pystan package. All three interfaces support sampling and optimization-based inference with diagnostics and posterior analysis. rstan and pystan also provide access to log probabilities, gradients, Hessians, parameter transforms, and specialized plotting.},
  number={1},
  journal={Journal of Statistical Software},
  author={Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year={2017},
  pages={1–32}
}

@misc{carpenter2015stan,
  title={The Stan Math Library: Reverse-Mode Automatic Differentiation in C++},
  author={Bob Carpenter and Matthew D. Hoffman and Marcus Brubaker and Daniel Lee and Peter Li and Michael Betancourt},
  year={2015},
  eprint={1509.07164},
  archivePrefix={arXiv},
  primaryClass={cs.MS},
  url={https://arxiv.org/abs/1509.07164}
}

@misc{lao2020,
  title={tfp.mcmc: Modern Markov Chain Monte Carlo Tools Built for Modern Hardware},
  author={Junpeng Lao and Christopher Suter and Ian Langmore and Cyril Chimisov and Ashish Saxena and Pavel Sountsov and Dave Moore and Rif A. Saurous and Matthew D. Hoffman and Joshua V. Dillon},
  year={2020},
  eprint={2002.01184},
  archivePrefix={arXiv},
  primaryClass={stat.CO},
  url={https://arxiv.org/abs/2002.01184}
}

@article{lunn2009,
  title={The BUGS project: Evolution, critique and future directions},
  author={Lunn, David and Spiegelhalter, David and Thomas, Andrew and Best, Nicky},
  journal={Statistics in medicine},
  volume={28},
  number={25},
  pages={3049--3067},
  year={2009},
  publisher={Wiley Online Library},
  doi={10.1002/sim.3680}
}

@inproceedings{plummer2003,
  title={JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling},
  author={Plummer, Martyn and others},
  booktitle={Proceedings of the 3rd international workshop on distributed statistical computing},
  volume={124},
  number={125.10},
  pages={1--10},
  year={2003},
  organization={Vienna, Austria.},
  pdf={https://www.r-project.org/conferences/DSC-2003/Proceedings/Plummer.pdf},
  url={https://www.r-project.org/conferences/DSC-2003/Proceedings/}
}


@article{cotter2013,
  title={MCMC methods for functions: modifying old algorithms to make them faster},
  author={Cotter, Simon L and Roberts, Gareth O and Stuart, Andrew M and White, David},
  journal={Statistical Science},
  pages={424--446},
  year={2013},
  publisher={JSTOR},
  doi={10.1214/13-STS421}
}


@article{kennedy2001,
  title={Bayesian calibration of computer models},
  author={Kennedy, Marc C and O'Hagan, Anthony},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={63},
  number={3},
  pages={425--464},
  year={2001},
  publisher={Wiley Online Library},
  doi={10.1111/1467-9868.00294}
}

@article{sargsyan2019embedded,
  title={Embedded model error representation for Bayesian model calibration},
  author={Sargsyan, Khachik and Huan, Xun and Najm, Habib N},
  journal={International Journal for Uncertainty Quantification},
  volume={9},
  number={4},
  year={2019},
  publisher={Begel House Inc.},
  doi={10.1615/Int.J.UncertaintyQuantification.2019027384}
}

@article{bardsley2014randomize,
  title={Randomize-then-optimize: A method for sampling from posterior distributions in nonlinear inverse problems},
  author={Bardsley, Johnathan M and Solonen, Antti and Haario, Heikki and Laine, Marko},
  journal={SIAM Journal on Scientific Computing},
  volume={36},
  number={4},
  pages={A1895--A1910},
  year={2014},
  publisher={SIAM},
  doi={10.1137/140964023}
}

@misc{detommaso2018stein,
  title={A Stein variational Newton method},
  author={Gianluca Detommaso and Tiangang Cui and Alessio Spantini and Youssef Marzouk and Robert Scheichl},
  year={2018},
  eprint={1806.03085},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/1806.03085}
}

@InProceedings{han2018stein,
  title = 	 {Stein Variational Gradient Descent Without Gradient},
  author =       {Han, Jun and Liu, Qiang},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1900--1908},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/han18b/han18b.pdf},
  url = 	 {https://proceedings.mlr.press/v80/han18b.html},
  abstract = 	 {Stein variational gradient decent (SVGD) has been shown to be a powerful approximate inference algorithm for complex distributions. However, the standard SVGD requires calculating the gradient of the target density and cannot be applied when the gradient is unavailable. In this work, we develop a gradient-free variant of SVGD (GF-SVGD), which replaces the true gradient with a surrogate gradient, and corrects the introduced bias by re-weighting the gradients in a proper form. We show that our GF-SVGD can be viewed as the standard SVGD with a special choice of kernel, and hence directly inherits all the theoretical properties of SVGD. We shed insights on the empirical choice of the surrogate gradient and further, propose an annealed GF-SVGD that consistently outperforms a number of recent advanced gradient-free MCMC methods in our empirical studies.}
}

@article{MLMCMC,
  author={Dodwell, Tim and Ketelsen, Chris and Scheichl, Robert and Teckentrup, Aretha},
  title={A hierarchical multilevel Markov chain Monte Carlo algorithm with applications to uncertainty quantification in subsurface flow},
  year={2015},
  pages={34 S.},
  language={eng},
  issn={2166-2525},
  volume={3},
  journal={SIAM ASA journal on uncertainty quantification},
  doi={10.1137/130915005},
}

@article{MLMCMCRevised,
author = {Dodwell, Tim and Ketelsen, Chris and Scheichl, Robert and Teckentrup, Aretha},
year = {2019},
month = {01},
pages = {509-545},
title = {Multilevel Markov Chain Monte Carlo},
volume = {61},
journal = {SIAM Review},
doi = {10.1137/19M126966X}
}

@article{conrad2013adaptive,
  title={Adaptive Smolyak pseudospectral approximations},
  author={Conrad, Patrick R and Marzouk, Youssef M},
  journal={SIAM Journal on Scientific Computing},
  volume={35},
  number={6},
  pages={A2643--A2670},
  year={2013},
  publisher={SIAM},
  doi={10.1137/120890715}
}


@article{conrad2018,
  title={Parallel local approximation MCMC for expensive models},
  author={Conrad, Patrick R and Davis, Andrew D and Marzouk, Youssef M and Pillai, Natesh S and Smith, Aaron},
  journal={SIAM/ASA Journal on Uncertainty Quantification},
  volume={6},
  number={1},
  pages={339--373},
  year={2018},
  publisher={SIAM},
  doi={10.1137/16M1084080}
}


@misc{davis2020rate,
  title={Rate-optimal refinement strategies for local approximation MCMC},
  author={Andrew D. Davis and Youssef Marzouk and Aaron Smith and Natesh Pillai},
  year={2021},
  eprint={2006.00032},
  archivePrefix={arXiv},
  primaryClass={stat.CO},
  url={https://arxiv.org/abs/2006.00032}
}

@article{parno2018transport,
  title={Transport map accelerated Markov chain Monte Carlo},
  author={Parno, Matthew D and Marzouk, Youssef M},
  journal={SIAM/ASA Journal on Uncertainty Quantification},
  volume={6},
  number={2},
  pages={645--682},
  year={2018},
  publisher={SIAM},
  doi={10.1137/17M1134640}
}

@article{MLMC,
author = {Giles, Michael B.},
title = {Multilevel Monte Carlo Path Simulation},
year = {2008},
issue_date = {May 2008},
publisher = {INFORMS},
address = {Linthicum, MD, USA},
volume = {56},
number = {3},
issn = {0030-364X},
url = {https://doi.org/10.1287/opre.1070.0496},
doi = {10.1287/opre.1070.0496},
abstract = {We show that multigrid ideas can be used to reduce the computational complexity of estimating an expected value arising from a stochastic differential equation using Monte Carlo path simulations. In the simplest case of a Lipschitz payoff and a Euler discretisation, the computational cost to achieve an accuracy of O(ε) is reduced from O(ε-3) to O(ε-2 (log ε)2). The analysis is supported by numerical results showing significant computational savings.},
journal = {Operations Research},
month = {may},
pages = {607–617},
numpages = {11},
keywords = {finance, computational complexity, simulation, efficiency, analysis of algorithms}
}

@misc{pybind11,
   author = {Wenzel Jakob and Jason Rhinelander and Dean Moldovan},
   year = {2017},
   howpublished={\url{https://github.com/pybind/pybind11}},
   title = {pybind11 -- Seamless operability between C++11 and Python}
}

@inproceedings{ParallelMLMCMC,
author = {Seelinger, Linus and Reinarz, Anne and Rannabauer, Leonhard and Bader, Michael and Bastian, Peter and Scheichl, Robert},
title = {High Performance Uncertainty Quantification with Parallelized Multilevel Markov Chain Monte Carlo},
year = {2021},
isbn = {9781450384421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458817.3476150},
doi = {10.1145/3458817.3476150},
abstract = {Numerical models of complex real-world phenomena often necessitate High Performance Computing (HPC). Uncertainties increase problem dimensionality further and pose even greater challenges.We present a parallelization strategy for multilevel Markov chain Monte Carlo, a state-of-the-art, algorithmically scalable Uncertainty Quantification (UQ) algorithm for Bayesian inverse problems, and a new software framework allowing for large-scale parallelism across forward model evaluations and the UQ algorithms themselves. The main scalability challenge presents itself in the form of strong data dependencies introduced by the MLMCMC method, prohibiting trivial parallelization.Our software is released as part of the modular and open-source MIT Uncertainty Quantification Library (MUQ), and can easily be coupled with arbitrary user codes. We demonstrate it using the Distributed and Unified Numerics Environment (DUNE) and the ExaHyPE Engine. The latter provides a realistic, large-scale tsunami model in which we identify the source of a tsunami from buoy-elevation data.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {75},
numpages = {15},
keywords = {bayesian inverse problems, tsunami simulation, ADER-DG, multilevel methods},
location = {St. Louis, Missouri},
series = {SC '21}
}
