---
title: Parallelized MLMC using MCMC components
layout: default
description: Shows how to implement parallelized Multilevel Monte Carlo type methods using the modular parallel MIMCMC stack. Allows easily runningMultilevel MC and Multilevel / Multiindex MCMC on the same model, using a common parallel architecture.
language: c++
tag: MCMC
doc_level: 1
---
<h1><small class="text-muted">Example</small> </br> Parallelized MLMC using MCMC components<h1>
<blockquote class="blockquote"><p class="mb-0">Shows how to implement parallelized Multilevel Monte Carlo type methods using the modular parallel MIMCMC stack. Allows easily runningMultilevel MC and Multilevel / Multiindex MCMC on the same model, using a common parallel architecture.</p></blockquote>
</br>



<pre class="prettyprint lang-cpp">
#include "MUQ/SamplingAlgorithms/SLMCMC.h"
#include "MUQ/SamplingAlgorithms/GreedyMLMCMC.h"
#include "MUQ/SamplingAlgorithms/MIMCMC.h"

#include "MUQ/Modeling/Distributions/Gaussian.h"
#include "MUQ/Modeling/Distributions/Density.h"

#include "MUQ/SamplingAlgorithms/DummyKernel.h"
#include "MUQ/SamplingAlgorithms/MHKernel.h"
#include "MUQ/SamplingAlgorithms/MHProposal.h"
#include "MUQ/SamplingAlgorithms/CrankNicolsonProposal.h"
#include "MUQ/SamplingAlgorithms/SamplingProblem.h"
#include "MUQ/SamplingAlgorithms/SubsamplingMIProposal.h"
#include "MUQ/SamplingAlgorithms/ParallelFixedSamplesMIMCMC.h"

#include &lt;boost/property_tree/ptree.hpp&gt;

namespace pt = boost::property_tree;
using namespace muq::Modeling;
using namespace muq::SamplingAlgorithms;
using namespace muq::Utilities;

#include "ParallelProblem.h"

int main(int argc, char **argv){

  MPI_Init(&argc, &argv);

  pt::ptree pt;

  pt.put("NumSamples_0", 1e4);
  pt.put("NumSamples_1", 5e3);
  pt.put("NumSamples_2", 1e3);
  pt.put("NumSamples_3", 5e2);
  pt.put("MLMCMC.Subsampling", 1);
  pt.put("MCMC.BurnIn", 10); // number of samples for single level
  pt.put("verbosity", 1); // show some output

/*{
  std::cout &lt;&lt; std::endl &lt;&lt; "*************** multilevel" &lt;&lt; std::endl &lt;&lt; std::endl;
  auto componentFactory = std::make_shared&lt;MyMIComponentFactory&gt;(pt);

  MIMCMC mimcmc(pt, componentFactory);
  mimcmc.Run();
  std::cout &lt;&lt; "mean QOI: " &lt;&lt; mimcmc.MeanQOI().transpose() &lt;&lt; std::endl;

  auto index_zero = std::make_shared&lt;MultiIndex&gt;(1);
  index_zero-&gt;SetValue(0, 0);
  std::cout &lt;&lt; "coarsest level mean QOI: " &lt;&lt; mimcmc.GetBox(index_zero)-&gt;FinestChain()-&gt;GetQOIs()-&gt;Mean().transpose() &lt;&lt; std::endl;
}


{
  std::cout &lt;&lt; std::endl &lt;&lt; "*************** single level reference" &lt;&lt; std::endl &lt;&lt; std::endl;
  auto index = componentFactory-&gt;FinestIndex();

  auto problem = componentFactory-&gt;SamplingProblem(index);
  auto proposal = componentFactory-&gt;Proposal(index, problem);

  std::vector&lt;std::shared_ptr&lt;TransitionKernel&gt;&gt; kernels(1);
  kernels[0] = std::make_shared&lt;DummyKernel&gt;(pt,problem,proposal);

  Eigen::VectorXd startingPoint = componentFactory-&gt;StartingPoint(index);

  auto mcmc = std::make_shared&lt;SingleChainMCMC&gt;(pt,kernels);
  mcmc-&gt;Run(startingPoint);
  std::cout &lt;&lt; "mean QOI: " &lt;&lt; mcmc-&gt;GetQOIs()-&gt;Mean().transpose() &lt;&lt; std::endl;
}*/

{
  auto comm = std::make_shared&lt;parcer::Communicator&gt;();

  auto componentFactory = std::make_shared&lt;MyMIComponentFactory&gt;(pt);
  StaticLoadBalancingMIMCMC parallelMIMCMC (pt, componentFactory);

  if (comm-&gt;GetRank() == 0) {
    parallelMIMCMC.Run();
    Eigen::VectorXd meanQOI = parallelMIMCMC.MeanQOI();
    std::cout &lt;&lt; "mean QOI: " &lt;&lt; meanQOI.transpose() &lt;&lt; std::endl;
    parallelMIMCMC.WriteToFile("samples.h5");
  }
  parallelMIMCMC.Finalize();

}

  MPI_Finalize();

  return 0;
}
</pre>
