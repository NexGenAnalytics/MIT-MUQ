---
title: DILI MCMC
layout: default
description: Demonstrates the basic usage of the Dimension Independent Likelihood Informed (DILI) MCMC algorithm.
language: python
tag: MCMC
doc_level: 1
---
<h1><small class="text-muted">Example</small> </br> DILI MCMC<h1>
<blockquote class="blockquote"><p class="mb-0">Demonstrates the basic usage of the Dimension Independent Likelihood Informed (DILI) MCMC algorithm.</p></blockquote>
</br>


<pre class="prettyprint" style="height:auto;max-height:400px;">
import muq.Modeling as mm
import muq.SamplingAlgorithms as ms
import muq.Approximation as ma
import muq.Utilities as mu
import muq.Optimization as mo

import matplotlib.pyplot as plt
import numpy as np

# Make sure the python path includes the DiffusionEquation model from the &quot;Modeling&quot; examples
import sys
sys.path.append(&#x27;../../../../Modeling/CustomModPiece/python&#x27;)

# Import a DiffusionEquation ModPiece from the CustomModPiece example
from CustomModPiece import DiffusionEquation

# The standard deviation of the additive Gaussian noise
noiseStd = 0.05

# Number of cells to use in Finite element discretization
numCells = 200

obsIndStart = 1
obsIndEnd = numCells
obsSkip = 20

obsMod = mm.SliceOperator(numCells+1,obsIndStart,obsIndEnd,obsSkip)

# The forward model
mod = DiffusionEquation(numCells)

# Create an exponential operator to transform log-conductivity into conductivity
rechargeVal = 10.0
recharge = mm.ConstantVector( rechargeVal*np.ones((numCells,)) )

# Combine the two models into a graph
graph = mm.WorkGraph()
graph.AddNode(mm.IdentityOperator(numCells), &quot;Log-Conductivity&quot;)
graph.AddNode(mm.ExpOperator(numCells), &quot;Conductivity&quot;)
graph.AddNode(recharge, &quot;Recharge&quot;)
graph.AddNode(mod,&quot;Forward Model&quot;)
graph.AddNode(obsMod, &quot;Observables&quot;)
graph.AddEdge(&quot;Log-Conductivity&quot;, 0, &quot;Conductivity&quot;, 0)
graph.AddEdge(&quot;Conductivity&quot;,0,&quot;Forward Model&quot;,0)
graph.AddEdge(&quot;Recharge&quot;,0,&quot;Forward Model&quot;,1)
graph.AddEdge(&quot;Forward Model&quot;,0,&quot;Observables&quot;,0)


# Set up the Gaussian process prior on the log-conductivity
gpKern = ma.SquaredExpKernel(1, 1.0, 0.3) + ma.MaternKernel(1, 0.1, 0.2, 1.0/2.0)
gpMean = ma.ZeroMean(1,1)
prior = ma.GaussianProcess(gpMean,gpKern).Discretize(mod.xs[0:-1].reshape(1,-1))
graph.AddNode(prior.AsDensity(), &quot;Prior&quot;)
graph.AddEdge(&quot;Log-Conductivity&quot;,0,&quot;Prior&quot;,0)

# Generate a &quot;true&quot; log conductivity and generate synthetic observations
trueLogK = prior.Sample()

trueHead = mod.Evaluate([np.exp(trueLogK), rechargeVal*np.ones((numCells,))])[0]
obsHead = obsMod.Apply(trueHead)[:,0] + noiseStd*mu.RandomGenerator.GetNormal(obsMod.rows())[:,0]

# Set up the likelihood and posterior
likely = mm.Gaussian(obsHead, noiseStd*noiseStd*np.ones((obsMod.rows(),)))
graph.AddNode(likely.AsDensity(),&quot;Likelihood&quot;)
graph.AddNode(mm.DensityProduct(2), &quot;Posterior&quot;)

graph.AddEdge(&quot;Observables&quot;,0,&quot;Likelihood&quot;,0)
graph.AddEdge(&quot;Prior&quot;,0,&quot;Posterior&quot;,0)
graph.AddEdge(&quot;Likelihood&quot;,0,&quot;Posterior&quot;,1)

graph.Visualize(&#x27;ModelGraph.png&#x27;)

#### MCMC Algorithm definition

# Basic options for MCMC and DILI
# NOTE: It might be cleaner in general to define these options in an external
#       YAML or XML file and read that file to construction the opts dictionary.

opts = dict()
opts[&#x27;NumSamples&#x27;] = 20000 # Number of MCMC steps to take
opts[&#x27;BurnIn&#x27;] = 0 # Number of steps to throw away as burn in
opts[&#x27;PrintLevel&#x27;] = 3 # in {0,1,2,3} Verbosity of the output
opts[&#x27;HessianType&#x27;] = &#x27;GaussNewton&#x27;  # Type of Hessian to use in DILI.  Either &quot;Exact&quot; or &quot;GaussNewton&quot;.  Note that the &quot;Exact&quot; Hessian is not always positive definite.
opts[&#x27;Adapt Interval&#x27;] = 500  # How often the LIS should be adapted.  If negative, the LIS computed at the intial point will be used and held constant
opts[&#x27;Adapt Start&#x27;] = 100 # The LIS will start being adapted after this many steps
opts[&#x27;Adapt End&#x27;] = 10000 # The LIS will stop being adapted after this many steps
opts[&#x27;Initial Weight&#x27;] = 100 # When the average Hessian is constructed, this represents the weight or &quot;number of samples&quot; given to the initial Hessian.

# Options for the LOBPCG generalized eigensolver used by DILI
eigOpts = dict()
eigOpts[&#x27;NumEigs&#x27;] = 200 # Maximum number of generalized eigenvalues to compute (e.g., maximum LIS dimension)
eigOpts[&#x27;RelativeTolerance&#x27;] = 1e-1 # Fraction of the largest eigenvalue used as stopping criteria on how many eigenvalues to compute
eigOpts[&#x27;AbsoluteTolerance&#x27;] = -100 # Minimum allowed eigenvalue
#eigOpts[&#x27;BlockSize&#x27;] = 30  # Number of eigenvalues computed simultaneously in LOBPCG.  Can be larger or smaller than NumEigs, but LOBPCG is generally more efficient if this is larger than NumEigs
#eigOpts[&#x27;MaxIts&#x27;] = 30 # Maximum number of iterations taken by LOBPCG within each block
eigOpts[&#x27;Verbosity&#x27;] = 3 # Controls how much information the solver prints to terminal

opts[&#x27;Eigensolver Block&#x27;] = &#x27;EigSolver&#x27; # Key in the opts dictionary where LOBPCG options are specified
opts[&#x27;EigSolver&#x27;] = eigOpts

# Options for the transition kernel employed in the LIS
lisOpts = dict()
lisOpts[&#x27;Method&#x27;] = &#x27;MHKernel&#x27;
lisOpts[&#x27;Proposal&#x27;] = &#x27;PropOpts&#x27; # Key in the lisOpts dictionary where proposal options are specified
lisOpts[&#x27;PropOpts.Method&#x27;] = &#x27;MALAProposal&#x27;
lisOpts[&#x27;PropOpts.StepSize&#x27;] = 0.1

opts[&#x27;LIS Block&#x27;] = &quot;LIS&quot; # Dictionary key where the LIS options are specified
opts[&#x27;LIS&#x27;] = lisOpts

# Options for the transition kernel employed in the CS
csOpts = dict()
csOpts[&#x27;Method&#x27;] = &#x27;MHKernel&#x27;
csOpts[&#x27;Proposal&#x27;] = &#x27;PropOpts&#x27; # Key in the csOpts dictionary where proposal options are specified
csOpts[&#x27;PropOpts.Method&#x27;] = &#x27;CrankNicolsonProposal&#x27;
csOpts[&#x27;PropOpts.Beta&#x27;] = 0.3 # Crank-Nicolson beta
csOpts[&#x27;PropOpts.PriorNode&#x27;] = &#x27;Prior&#x27; # Name of the prior node in the graph constructed above

opts[&#x27;CS Block&#x27;] =  &quot;CS&quot; # Dictionary key where the CS options are specified
opts[&#x27;CS&#x27;] = csOpts


### Set up the sampling problem
postDens = graph.CreateModPiece(&quot;Posterior&quot;)
likely = graph.CreateModPiece(&quot;Likelihood&quot;)
prior = graph.CreateModPiece(&quot;Prior&quot;)
problem = ms.SamplingProblem(postDens)

# Construct the DILI Kernel based on the options specified above
kern = ms.DILIKernel(opts, problem)

# Construct the MCMC sampler using this transition kernel
sampler = ms.SingleChainMCMC(opts, [kern])

# Run the MCMC sampler
x0 = [trueLogK]
samps = sampler.Run(x0)

# Extract the posteior samples as a matrix and compute some posterior statistics
sampMat = samps.AsMatrix()

postMean = np.mean(sampMat,axis=1)
q05 = np.percentile(sampMat,5,axis=1)
q95 = np.percentile(sampMat,95,axis=1)

# Plot the results
fig, axs = plt.subplots(ncols=3,nrows=2, figsize=(12,8))
axs[0,0].plot(mod.xs, trueHead, label=&#x27;True Head&#x27;)
axs[0,0].plot(mod.xs[obsIndStart:obsIndEnd:obsSkip],obsHead,&#x27;.k&#x27;,label=&#x27;Observed Head&#x27;)
axs[0,0].legend()
axs[0,0].set_title(&#x27;Data&#x27;)
axs[0,0].set_xlabel(&#x27;Position, $x$&#x27;)
axs[0,0].set_ylabel(&#x27;Hydraulic head $h(x)$&#x27;)

axs[0,1].fill_between(mod.xs[0:-1], q05, q95, alpha=0.5,label=&#x27;5%-95% CI&#x27;)
axs[0,1].plot(mod.xs[0:-1],postMean, label=&#x27;Posterior Mean&#x27;)
axs[0,1].plot(mod.xs[0:-1],trueLogK,label=&#x27;Truth&#x27;)
axs[0,1].legend()
axs[0,1].set_title(&#x27;Posterior on log(K)&#x27;)
axs[0,1].set_xlabel(&#x27;Position, $x$&#x27;)
axs[0,1].set_ylabel(&#x27;Log-Conductivity $log(K(x))$&#x27;)

axs[0,2].plot(sampMat[0,:], label=&#x27;$log K_0$&#x27;)
axs[0,2].plot(sampMat[100,:],label=&#x27;$log K_{100}$&#x27;)
axs[0,2].plot(sampMat[190,:],label=&#x27;$log K_{190}$&#x27;)
axs[0,2].set_title(&#x27;MCMC Trace&#x27;)
axs[0,2].set_xlabel(&#x27;MCMC Iteration (after burnin)&#x27;)
axs[0,2].set_ylabel(&#x27;Log-Conductivity&#x27;)

axs[1,0].scatter(sampMat[1,:],sampMat[0,:],edgeColor=&#x27;None&#x27;,alpha=0.02)
axs[1,0].set_xlabel(&#x27;$log K_1$&#x27;)
axs[1,0].set_ylabel(&#x27;$log K_0$&#x27;)
axs[1,1].scatter(sampMat[10,:],sampMat[0,:],edgeColor=&#x27;None&#x27;,alpha=0.02)
axs[1,1].set_xlabel(&#x27;$log K_{10}$&#x27;)
axs[1,2].scatter(sampMat[20,:],sampMat[0,:],edgeColor=&#x27;None&#x27;,alpha=0.02)
axs[1,2].set_xlabel(&#x27;$log K_{20}$&#x27;)


lisVecs = kern.LISVecs()
lisVals = kern.LISVals()

fig3 = plt.figure(figsize=(12,5))
gs = fig3.add_gridspec(1, 3)

ax1 = fig3.add_subplot(gs[0, 0])
ax2 = fig3.add_subplot(gs[0, 1:])

ax1.plot(lisVals,&#x27;.&#x27;,markersize=10)
ax1.plot([0,len(lisVals)], [eigOpts[&#x27;RelativeTolerance&#x27;]*lisVals[0], eigOpts[&#x27;RelativeTolerance&#x27;]*lisVals[0]],&#x27;--k&#x27;)

ax1.set_ylabel(&#x27;$\lambda_i$&#x27;)
ax1.set_xlabel(&#x27;Index $i$&#x27;)
ax1.set_title(&#x27;Generalized Eigenvalues&#x27;)

for i in range(lisVecs.shape[1]):
    ax2.plot(mod.xs[0:-1], lisVecs[:,i])
ax2.set_title(&#x27;Generalized Eigenvectors&#x27;)
ax2.set_xlabel(&#x27;Position $x$&#x27;)
ax2.set_ylabel(&#x27;$v_i$&#x27;)


plt.show()

</pre>

